{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-38d35c198d4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load the adjacency matrix into a numpy array.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnormal_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Normal.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mnormal_mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mG_Normal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormal_mat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the adjacency matrix into a numpy array.\n",
    "normal_mat = np.loadtxt('../Normal.txt', dtype=int)\n",
    "for i in range(0,70):\n",
    "        normal_mat[i][i] = 0\n",
    "G_Normal = nx.from_numpy_matrix(normal_mat)\n",
    "print(\"Number Of Edges: \",len(G_Normal.edges()))\n",
    "print(\"Number Of Nodes: \",len(G_Normal.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Edges:  1510\n",
      "Number Of Nodes:  70\n"
     ]
    }
   ],
   "source": [
    "# Load the adjacency matrix into a numpy array.\n",
    "eMCI_mat = np.loadtxt('../eMCI.txt', dtype=int)\n",
    "for i in range(0,70):\n",
    "        eMCI_mat[i][i] = 0\n",
    "G_eMCI = nx.from_numpy_matrix(eMCI_mat)\n",
    "print(\"Number Of Edges: \",len(G_eMCI.edges()))\n",
    "print(\"Number Of Nodes: \",len(G_eMCI.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Edges:  1380\n",
      "Number Of Nodes:  70\n"
     ]
    }
   ],
   "source": [
    "lmci_mat = np.loadtxt('../lMCI.txt', dtype=int)\n",
    "#removing self loops\n",
    "for i in range(0,70):\n",
    "        lmci_mat[i][i] = 0\n",
    "G_lMCI = nx.from_numpy_matrix(lmci_mat)\n",
    "print(\"Number Of Edges: \",len(G_lMCI.edges()))\n",
    "print(\"Number Of Nodes: \",len(G_lMCI.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Edges:  1364\n",
      "Number Of Nodes:  70\n"
     ]
    }
   ],
   "source": [
    "# Load the adjacency matrix into a numpy array.\n",
    "ad_mat = np.loadtxt('../AD.txt', dtype=int)\n",
    "for i in range(0,70):\n",
    "        ad_mat[i][i] = 0\n",
    "G_AD = nx.from_numpy_matrix(ad_mat)\n",
    "print(\"Number Of Edges: \",len(G_AD.edges()))\n",
    "print(\"Number Of Nodes: \",len(G_AD.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal complement\n",
    "G_Normal_complement = nx.complement(G_Normal)\n",
    "normal_mat_complement = nx.adjacency_matrix(G_Normal_complement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eMCI complement\n",
    "G_eMCI_complement = nx.complement(G_eMCI)\n",
    "emci_mat_complement = nx.adjacency_matrix(G_eMCI_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eMCI complement\n",
    "G_lMCI_complement = nx.complement(G_lMCI)\n",
    "lmci_mat_complement = nx.adjacency_matrix(G_lMCI_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eMCI complement\n",
    "G_AD_complement = nx.complement(G_AD)\n",
    "ad_mat_complement = nx.adjacency_matrix(G_AD_complement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Edge_List(Graph):\n",
    "    edges = list(Graph.edges)\n",
    "    node_list_1 = [item[0] for item in edges]\n",
    "    node_list_2 = [item[1] for item in edges]\n",
    "    # combine all nodes in a list\n",
    "    node_list = node_list_1 + node_list_2\n",
    "    # remove duplicate items from the list\n",
    "    node_list = list(dict.fromkeys(node_list))\n",
    "    df = pd.DataFrame({'node_1': node_list_1, 'node_2': node_list_2})\n",
    "    return df,node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_Normal,edgeList_Normal = Edge_List(G_Normal)\n",
    "edges_EMCI,edgeList_EMCI = Edge_List(G_eMCI)\n",
    "edges_LMCI,edgeList_LMCI = Edge_List(G_lMCI)\n",
    "edges_AD,edgeList_AD = Edge_List(G_AD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_Normal_complement,edgeList_Normal_complement = Edge_List(G_Normal_complement)\n",
    "edges_EMCI_complement,edgeList_EMCI_complement = Edge_List(G_eMCI_complement)\n",
    "edges_LMCI_complement,edgeList_LMCI_complement = Edge_List(G_lMCI_complement)\n",
    "edges_AD_complement,edgeList_AD_complement = Edge_List(G_AD_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recreate the graph\n",
    "def recreateGraph(e_df,node_list):\n",
    "    G = nx.from_pandas_edgelist(e_df, \"node_1\", \"node_2\", create_using=nx.Graph())\n",
    "    adj_G = nx.to_numpy_matrix(G,nodelist = node_list)\n",
    "    return G,adj_G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_Normal_complement,adj_normal_complement = recreateGraph(edges_Normal_complement,edgeList_Normal_complement)\n",
    "G_EMCI_complement,adj_emci_complement = recreateGraph(edges_EMCI_complement,edgeList_EMCI_complement)\n",
    "G_LMCI_complement,adj_lmci_complement = recreateGraph(edges_LMCI_complement,edgeList_LMCI_complement)\n",
    "G_AD_complement,adj_ad_complement = recreateGraph(edges_AD_complement,edgeList_AD_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_Normal_,adj_normal = recreateGraph(edges_Normal,edgeList_Normal)\n",
    "G_EMCI,adj_emci = recreateGraph(edges_EMCI,edgeList_EMCI)\n",
    "G_LMCI,adj_lmci = recreateGraph(edges_LMCI,edgeList_LMCI)\n",
    "G_AD,adj_ad = recreateGraph(edges_AD,edgeList_AD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Dataset(Graph,G_data):\n",
    "    AA = []\n",
    "    PA = []\n",
    "    RAI = []\n",
    "    JC = []\n",
    "    CSH = []\n",
    "    RAISH = []\n",
    "    WIC = []\n",
    "    CN=[]\n",
    "    for i,j in zip(G_data['node_1'],G_data['node_2']):\n",
    "        AA.append(list(nx.adamic_adar_index(Graph,ebunch=[(i,j)]))[0][2])\n",
    "        RAI.append(list(nx.resource_allocation_index(Graph,ebunch=[(i,j)]))[0][2])\n",
    "        PA.append(list(nx.preferential_attachment(Graph,ebunch=[(i,j)]))[0][2])\n",
    "        JC.append(list(nx.jaccard_coefficient(Graph,ebunch=[(i,j)]))[0][2])\n",
    "        CN.append(len(list(nx.common_neighbors(Graph, i, j))))\n",
    "        #CNC.append(list(nx.common_neighbor_centrality(G, ebunch=[(i, j)]))[0][2])\n",
    "    G_data['AA'] = AA     \n",
    "    G_data['RAI'] = RAI\n",
    "    G_data['PA'] = PA\n",
    "    G_data['JC'] = JC \n",
    "    G_data['CN'] = CN\n",
    "   \n",
    "    #df_AllNodes['CNC'] = CNC \n",
    "    return G_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Dataset_for_pred(Graph):\n",
    "    edges = list(Graph.edges)\n",
    "    node_list_1 = [item[0] for item in edges]\n",
    "    node_list_2 = [item[1] for item in edges]\n",
    "    # combine all nodes in a list\n",
    "    node_list = node_list_1 + node_list_2\n",
    "\n",
    "    # remove duplicate items from the list\n",
    "    node_list = list(dict.fromkeys(node_list))\n",
    "    G_data = pd.DataFrame()\n",
    "    AA = []\n",
    "    PA = []\n",
    "    RAI = []\n",
    "    JC = []\n",
    "    CSH = []\n",
    "    RAISH = []\n",
    "    WIC = []\n",
    "    CN=[]\n",
    "    _node1 = []\n",
    "    _node2 = []\n",
    "    target = []\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i != j:\n",
    "                _node1.append(i)\n",
    "                _node2.append(j)\n",
    "                AA.append(list(nx.adamic_adar_index(Graph,ebunch=[(i,j)]))[0][2])\n",
    "                RAI.append(list(nx.resource_allocation_index(Graph,ebunch=[(i,j)]))[0][2])\n",
    "                PA.append(list(nx.preferential_attachment(Graph,ebunch=[(i,j)]))[0][2])\n",
    "                JC.append(list(nx.jaccard_coefficient(Graph,ebunch=[(i,j)]))[0][2])\n",
    "                CN.append(len(list(nx.common_neighbors(Graph, i, j))))\n",
    "                #CNC.append(list(nx.common_neighbor_centrality(G, ebunch=[(i, j)]))[0][2])\n",
    "                if Graph.has_edge(i,j)==True:\n",
    "                    target.append(1)\n",
    "                else:\n",
    "                    target.append(0)\n",
    "    G_data['node1'] = _node1\n",
    "    G_data['node2'] = _node2     \n",
    "    G_data['AA'] = AA     \n",
    "    G_data['RAI'] = RAI\n",
    "    G_data['PA'] = PA\n",
    "    G_data['JC'] = JC \n",
    "    G_data['CN'] = CN\n",
    "    G_data['Target'] = target\n",
    "   \n",
    "    #df_AllNodes['CNC'] = CNC \n",
    "    return G_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataSet(Graph,adj_G):\n",
    "    edges = list(Graph.edges)\n",
    "    node_list_1 = [item[0] for item in edges]\n",
    "    node_list_2 = [item[1] for item in edges]\n",
    "    # combine all nodes in a list\n",
    "    node_list = node_list_1 + node_list_2\n",
    "    # remove duplicate items from the list\n",
    "    node_list = list(dict.fromkeys(node_list))\n",
    "    G_df = pd.DataFrame({'node_1': node_list_1, 'node_2': node_list_2})\n",
    "    # get unconnected node-pairs\n",
    "    \n",
    "    all_unconnected_pairs = []\n",
    "    # traverse adjacency matrix\n",
    "    offset = 0\n",
    "    for i in tqdm(range(adj_G.shape[0])):\n",
    "        for j in range(offset,adj_G.shape[1]):\n",
    "            if i != j:\n",
    "                if adj_G[i,j] == 0:\n",
    "                    all_unconnected_pairs.append([node_list[i],node_list[j]])\n",
    "\n",
    "        offset = offset + 1\n",
    "    node_1_unlinked = [i[0] for i in all_unconnected_pairs]\n",
    "    node_2_unlinked = [i[1] for i in all_unconnected_pairs]\n",
    "    data = pd.DataFrame({'node_1':node_1_unlinked, \n",
    "                         'node_2':node_2_unlinked})\n",
    "    # add target variable 'link'\n",
    "    data['link'] = 0\n",
    "    initial_node_count = len(Graph.nodes)\n",
    "\n",
    "    G_df_temp = G_df.copy()\n",
    "    # empty list to store removable links\n",
    "    omissible_links_index = []\n",
    "    for i in tqdm(G_df.index.values):\n",
    "      # remove a node pair and build a new graph\n",
    "      G_temp = nx.from_pandas_edgelist(G_df_temp.drop(index = i), \"node_1\", \"node_2\", create_using=nx.Graph())\n",
    "      # check there is no spliting of graph and number of nodes is same\n",
    "      if (nx.number_connected_components(G_temp) == 1) and (len(G_temp.nodes) == initial_node_count):\n",
    "        omissible_links_index.append(i)\n",
    "        G_df_temp = G_df_temp.drop(index = i)\n",
    "    # create dataframe of removable edges\n",
    "    G_df_ghost = G_df.loc[omissible_links_index]\n",
    "    # add the target variable 'link'\n",
    "    G_df_ghost['link'] = 1\n",
    "    data = data.append(G_df_ghost[['node_1', 'node_2', 'link']], ignore_index=True)\n",
    "    # drop removable edges\n",
    "    G_df_partial = G_df.drop(index=G_df_ghost.index.values)\n",
    "    # build graph\n",
    "    G_data = nx.from_pandas_edgelist(G_df_partial, \"node_1\", \"node_2\", create_using=nx.Graph())\n",
    "    return data,G_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_(G_first,G_sec,adj_mat):\n",
    "    data,G_data = prepareDataSet(G_first,adj_mat)\n",
    "    df = create_Dataset(G_data,data)\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(df[['AA','RAI','PA','JC','CN']], df['link'], test_size = 0.3, random_state = 35)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(xtrain, ytrain)\n",
    "    predictions = lr.predict(xtest)\n",
    "    #roc_auc_score(ytest, predictions[:,1])\n",
    "    print(\"Test accuracy\",accuracy_score(ytest,predictions))\n",
    "    first_dataset = create_Dataset_for_pred(G_first)\n",
    "    second_dataset = create_Dataset_for_pred(G_sec)\n",
    "    predictions = lr.predict(first_dataset[['AA','RAI','PA','JC','CN']])\n",
    "    #roc_auc_score(ytest, predictions[:,1])\n",
    "    print(\"predictions :\\n\",predictions)\n",
    "    print(\"Training accuracy\",accuracy_score(first_dataset['Target'],predictions))\n",
    "    print(\"Next state prediction accuracy\",accuracy_score(second_dataset['Target'],predictions))\n",
    "    print(\"Confusion matrix: \\n\",confusion_matrix(second_dataset['Target'],predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing pipeline on actual graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 4353.13it/s]\n",
      "100%|██████████| 1490/1490 [00:08<00:00, 169.76it/s]\n",
      "C:\\Users\\Divay Mohan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.6400602409638554\n",
      "predictions :\n",
      " [0 0 0 ... 0 0 0]\n",
      "Training accuracy 0.34591747146619845\n",
      "Next state prediction accuracy 0.33713784021071114\n",
      "Confusion matrix: \n",
      " [[1536    0]\n",
      " [3020    0]]\n"
     ]
    }
   ],
   "source": [
    "model_(G_Normal,G_EMCI,adj_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 6699.06it/s]\n",
      "100%|██████████| 1510/1510 [00:09<00:00, 155.54it/s]\n",
      "C:\\Users\\Divay Mohan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.6445783132530121\n",
      "predictions :\n",
      " [0 0 0 ... 0 0 0]\n",
      "Training accuracy 0.33713784021071114\n",
      "Next state prediction accuracy 0.3942054433713784\n",
      "Confusion matrix: \n",
      " [[1796    0]\n",
      " [2760    0]]\n"
     ]
    }
   ],
   "source": [
    "model_(G_EMCI,G_LMCI,adj_emci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 6563.40it/s]\n",
      "100%|██████████| 1380/1380 [00:10<00:00, 135.68it/s]\n",
      "C:\\Users\\Divay Mohan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.6039156626506024\n",
      "predictions :\n",
      " [0 0 0 ... 0 0 0]\n",
      "Training accuracy 0.3942054433713784\n",
      "Next state prediction accuracy 0.40122914837576823\n",
      "Confusion matrix: \n",
      " [[1828    0]\n",
      " [2728    0]]\n"
     ]
    }
   ],
   "source": [
    "model_(G_LMCI,G_AD,adj_lmci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 6705.05it/s]\n",
      "100%|██████████| 1490/1490 [00:07<00:00, 190.97it/s]\n",
      "C:\\Users\\Divay Mohan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.6400602409638554\n",
      "predictions :\n",
      " [0 0 0 ... 0 0 0]\n",
      "Training accuracy 0.34591747146619845\n",
      "Next state prediction accuracy 0.40122914837576823\n",
      "Confusion matrix: \n",
      " [[1828    0]\n",
      " [2728    0]]\n"
     ]
    }
   ],
   "source": [
    "model_(G_Normal,G_AD,adj_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing pipeline on complemented graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<00:00, 3728.47it/s]\n",
      "100%|██████████| 788/788 [00:05<00:00, 149.17it/s]\n",
      "C:\\Users\\Divay Mohan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.6716867469879518\n",
      "predictions :\n",
      " [0 1 1 ... 0 0 0]\n",
      "Training accuracy 0.8024582967515365\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4830, 4556]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-dcf6ada40c6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_Normal_complement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG_EMCI_complement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madj_normal_complement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-e34596dd3649>\u001b[0m in \u001b[0;36mmodel_\u001b[1;34m(G_first, G_sec, adj_mat)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predictions :\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Next state prediction accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Confusion matrix: \\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4830, 4556]"
     ]
    }
   ],
   "source": [
    "model_(G_Normal_complement,G_EMCI_complement,adj_normal_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<?, ?it/s]\n",
      "100%|██████████| 905/905 [00:06<00:00, 137.30it/s]\n",
      "C:\\Users\\Divay Mohan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.6534090909090909\n",
      "predictions :\n",
      " [0 0 0 ... 0 0 0]\n",
      "Training accuracy 0.6252587991718427\n",
      "Next state prediction accuracy 0.5714285714285714\n",
      "Confusion matrix: \n",
      " [[2760    0]\n",
      " [2070    0]]\n"
     ]
    }
   ],
   "source": [
    "model_(G_EMCI_complement,G_LMCI_complement,adj_emci_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 3436.34it/s]\n",
      "100%|██████████| 1035/1035 [00:09<00:00, 114.11it/s]\n",
      "C:\\Users\\Divay Mohan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.5923295454545454\n",
      "predictions :\n",
      " [0 0 0 ... 0 0 0]\n",
      "Training accuracy 0.5714285714285714\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4556, 4830]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-6a717ee083c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG_LMCI_complement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG_AD_complement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madj_lmci_complement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-e34596dd3649>\u001b[0m in \u001b[0;36mmodel_\u001b[1;34m(G_first, G_sec, adj_mat)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predictions :\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Next state prediction accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Confusion matrix: \\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4556, 4830]"
     ]
    }
   ],
   "source": [
    "model_(G_LMCI_complement,G_AD_complement,adj_lmci_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:00<?, ?it/s]\n",
      "100%|██████████| 788/788 [00:04<00:00, 183.72it/s]\n",
      "C:\\Users\\Divay Mohan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.6716867469879518\n",
      "predictions :\n",
      " [0 1 1 ... 0 0 0]\n",
      "Training accuracy 0.8024582967515365\n",
      "Next state prediction accuracy 0.6549604916593503\n",
      "Confusion matrix: \n",
      " [[1696 1032]\n",
      " [ 540 1288]]\n"
     ]
    }
   ],
   "source": [
    "model_(G_Normal_complement,G_AD_complement,adj_normal_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
